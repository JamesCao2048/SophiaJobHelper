# HCI Density Strategy Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** å°† HCI ç ”ç©¶è€…å¯†åº¦ç»´åº¦èå…¥ overseas_pipeline çš„ Step 1/2/3ï¼Œå®ç°è‡ªåŠ¨åˆ†ç±»ã€è¯¾ç¨‹æŠ“å–ã€ç­–ç•¥é©±åŠ¨ææ–™ç”Ÿæˆã€‚

**Architecture:** æ–°å¢ç‹¬ç«‹ç­–ç•¥æ–‡ä»¶ï¼ˆè¢« agent è¯»å–ï¼‰+ ä¸¤ä¸ª Python è„šæœ¬ï¼ˆcode åšç¡®å®šæ€§å·¥ä½œï¼‰+ æ›´æ–° CLAUDE.md æµç¨‹æŒ‡ä»¤ã€‚agent å’Œ code åˆ†å·¥ï¼šcode è´Ÿè´£å…³é”®è¯åŒ¹é…/è®¡æ•°/ç»“æ„åŒ–ï¼Œagent è´Ÿè´£è¾¹ç•Œåˆ¤æ–­/ç­–ç•¥å™äº‹/ææ–™ç”Ÿæˆã€‚

**Tech Stack:** Python 3.10+ï¼ˆæ ‡å‡†åº“ + requestsï¼‰ã€JSONã€Markdownã€Bashï¼ˆcurl + Tavily APIï¼‰

**Design Doc:** `docs/plans/2026-02-19-hci-density-strategy-design.md`

---

## Task 1: åˆ›å»º HCI å¯†åº¦ç­–ç•¥æ–‡ä»¶

**Files:**
- Create: `overseas_pipeline/strategies/hci_density_strategy.md`

**Step 1: åˆ›å»ºç›®å½•**
```bash
mkdir -p overseas_pipeline/strategies
```

**Step 2: å†™å…¥ç­–ç•¥æ–‡ä»¶**

å†…å®¹å¦‚ä¸‹ï¼ˆå®Œæ•´å†™å…¥ï¼‰ï¼š

```markdown
# HCI å¯†åº¦ç­–ç•¥æŒ‡å—

æœ¬æ–‡ä»¶è¢« Step 2ï¼ˆåˆ†æï¼‰å’Œ Step 3ï¼ˆææ–™ç”Ÿæˆï¼‰è¯»å–ï¼Œæ ¹æ®ç›®æ ‡é™¢ç³» HCI ç ”ç©¶è€…å¯†åº¦æŒ‡å¯¼ç”³è¯·ææ–™çš„ä¿®è¾ç­–ç•¥ã€‚

## ä¸€ã€å¯†åº¦ç­‰çº§å®šä¹‰

| level | äººæ•° | å«ä¹‰ |
|:------|:-----|:-----|
| `none` | 0 | æ—  HCI ç ”ç©¶è€… |
| `few` | 1â€“3 | å°è§„æ¨¡ HCI é›†ç¾¤ |
| `many` | >3 | æˆç†Ÿ HCI å›¢é˜Ÿ |

## äºŒã€ç»„åˆç­–ç•¥çŸ©é˜µ

åŒå±‚åˆ†ç±»ï¼ˆç›®æ ‡ç³» Ã— å­¦é™¢ï¼‰å†³å®šç­–ç•¥æ ‡ç­¾ï¼š

| ç›®æ ‡ç³» \ å­¦é™¢ | **none** | **few** | **many** |
|:-------------|:---------|:--------|:---------|
| **none** | `pure_pioneer` | `pioneer_with_few_allies` | `pioneer_with_allies` |
| **few** | ç½•è§ | `builder` | `builder_in_rich_ecosystem` |
| **many** | â€” | â€” | `specialist` |

## ä¸‰ã€å„ç­–ç•¥è¯¦ç»†æŒ‡å—

### pure_pioneerï¼ˆtarget=none, faculty=noneï¼‰

**äººè®¾ï¼š** å¼€æ‹“è€…ã€‚é™¢ç³»æ‰€æœ‰è¯„å§”éƒ½æ˜¯é HCI äººå£«ã€‚

#### Cover Letter
- å…¨é¢æŠ€æœ¯ä¼ªè£…ï¼šé¿å… "HCI"ã€"ç”¨æˆ·ä½“éªŒ" ç­‰æ„Ÿæ€§è¯æ±‡
  - âœ… "human-in-the-loop computing" / "interactive systems architecture"
  - âŒ "UX research" / "design thinking"
- è®ºè¯ HCI å¯¹é™¢ç³»çš„**å¢é‡ä»·å€¼**ï¼šå¯ç”³è¯·ç¤¾ç§‘/åŒ»å­¦åŸºé‡‘ï¼ˆä¼ ç»Ÿ CS éš¾è§¦åŠï¼‰
- ç‚¹åç›®æ ‡ç³»å†…æœ‰ç ”ç©¶äº¤é›†çš„æ•™æˆï¼ˆå³ä½¿é HCI æ–¹å‘ï¼‰

#### Research Statement
- "ç¡¬åŒ–"å¤„ç†ï¼šç³»ç»Ÿæ¶æ„å›¾ > ç”¨æˆ·å¼•è¯­ï¼›å¼ºè°ƒç®—æ³•/æ¨¡å‹/ç³»ç»Ÿè´¡çŒ®
- åŠ å…¥"æ–¹æ³•è®ºä¸¥è°¨æ€§"æ®µè½ï¼Œè§£é‡Šç”¨æˆ·ç ”ç©¶çš„ç§‘å­¦æ€§
- å¼ºè°ƒé‡åŒ–æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€æ•ˆç‡æå‡ç­‰ï¼‰

#### Teaching Statement
- **å¿…é¡»**åˆ— CS æ ¸å¿ƒè¯¾ï¼ˆæ•°æ®ç»“æ„ã€è½¯å·¥ã€ç®—æ³•ã€ç¦»æ•£æ•°å­¦ç­‰ï¼‰
- ä»ç›®æ ‡ç³» course catalog ä¸­é€‰å‡º Sophia èƒ½æ•™çš„å…·ä½“è¯¾ç¨‹ï¼ˆåˆ—è¯¾ç¨‹ç¼–å·å’Œåç§°ï¼‰
- HCI è¯¾ç¨‹ä½œä¸º"å¯å¼€è®¾çš„æ–°è¯¾"è€Œéä¸»æ‰“

#### ç»è´¹å™äº‹
- "æˆ‘çš„åŠ å…¥å°†ä¸ºé™¢ç³»æ‰“å¼€æ–°çš„ç»è´¹æ¸ é“ï¼ˆNSF SBE / ARC ç¤¾ä¼šç§‘å­¦æ¿å— / åŒ»å­¦åŸºé‡‘ï¼‰"

---

### pioneer_with_few_alliesï¼ˆtarget=none, faculty=fewï¼‰

**äººè®¾ï¼š** å¼€æ‹“è€… + å°‘é‡ç›Ÿå‹ã€‚å­¦é™¢æœ‰ 1â€“3 ä½ HCI æ•™æˆï¼Œå¯ä½œä¸ºåˆä½œå™äº‹çš„é”šç‚¹ã€‚

#### Cover Letter
- æŠ€æœ¯ç¡¬æ ¸åŸºè°ƒæ‰“åº•ï¼ˆåŒ pure_pioneerï¼‰
- ç”¨ä¸€æ®µè¡¥å……è·¨ç³»åˆä½œï¼šç‚¹åå·²æœ‰ HCI æ•™æˆï¼Œè¯´æ˜äº’è¡¥æ€§
- æ³¨æ„ï¼šç›Ÿå‹å°‘ï¼Œä¸èƒ½è¿‡åº¦ä¾èµ–è·¨ç³»å™äº‹

#### Research Statement / Teaching Statement
- åŒ pure_pioneerï¼Œä½†å¯åœ¨æœªæ¥è®¡åˆ’ä¸­æåŠä¸å·²æœ‰ HCI æ•™æˆçš„åˆä½œ

---

### pioneer_with_alliesï¼ˆtarget=none, faculty=manyï¼‰

**äººè®¾ï¼š** å¼€æ‹“è€… + å¼ºç›Ÿå‹ã€‚æœ€å¤æ‚åœºæ™¯â€”â€”ç›®æ ‡ç³»æ—  HCIï¼Œä½†å­¦é™¢æœ‰æˆç†Ÿ HCI å›¢é˜Ÿã€‚

**æ ¸å¿ƒçŸ›ç›¾ï¼š** å¿…é¡»åŒæ—¶è¯´æœä¸¤ç¾¤äººï¼š
- ç›®æ ‡ç³» CS è¯„å§”ï¼šä¸æ‡‚ HCIï¼Œéœ€è¦æŠ€æœ¯ä¼ªè£…
- å­¦é™¢ HCI æ•™æˆï¼ˆå¯èƒ½ä½œä¸ºå¤–éƒ¨è¯„å®¡ï¼‰ï¼šæ‡‚ HCIï¼Œè¯„åˆ¤åˆä½œæ½œåŠ›

**å…³é”®é™·é˜±ï¼š** ä¸èƒ½è®©äººè§‰å¾—"ä½ åº”è¯¥å» HCI ç³»è€Œä¸æ˜¯ç›®æ ‡ç³»"ã€‚

#### Cover Letter
- æŠ€æœ¯ç¡¬æ ¸åŸºè°ƒæ‰“åº•
- ç”¨ä¸€æ®µä¸“è®²è·¨ç³»åˆä½œï¼š**ä¼˜å…ˆç‚¹åç›®æ ‡ç³»å†…æœ‰äº¤é›†çš„æ•™æˆ**ï¼Œä¸å¤Ÿæ—¶è¡¥å……å…¶ä»–ç³» HCI æ•™æˆ
- å¿…é¡»è®ºè¯ï¼šä¸ºä»€ä¹ˆä½ çš„å·¥ä½œå±äºç›®æ ‡ç³»ï¼ˆä¾‹ï¼š"agentic AI çš„ human evaluation æ–¹æ³•è®ºæ˜¯ AI ç³»çš„æ ¸å¿ƒéœ€æ±‚ï¼Œè€Œé HCI ç³»çš„è¾¹ç•Œè¯¾é¢˜"ï¼‰

#### Research Statement
- "ç¡¬åŒ–"è¯­è¨€ä¸ºä¸»ï¼ˆä¸º CS è¯„å§”ï¼‰
- åŠ  "Cross-departmental synergies" æ®µè½ï¼ˆç‚¹å HCI æ•™æˆåŠå…·ä½“åˆä½œæ–¹å‘ï¼‰
- ç‚¹åç­–ç•¥åŒ Cover Letter

#### Teaching Statement
- CS æ ¸å¿ƒè¯¾èƒ½åŠ› + ç›®æ ‡ç³» catalog ä¸­çš„å…·ä½“è¯¾ç¨‹
- æå‡ºä¸ HCI ç³»**è”åˆå¼€è¯¾**çš„å¯èƒ½æ€§ï¼ˆä½œä¸ºåŠ åˆ†é¡¹ï¼Œä¸æ˜¯ä¸»æ‰“ï¼‰

---

### builderï¼ˆtarget=few, faculty=fewï¼‰

**äººè®¾ï¼š** å»ºè®¾è€…ã€‚é™¢ç³»å·²æœ‰å°è§„æ¨¡ HCI é›†ç¾¤ï¼Œæ€¥éœ€æ‰©å……ã€‚

#### Cover Letter
- æ˜ç¡®ç‚¹åç°æœ‰ HCI æ•™æˆï¼Œé˜è¿°ç ”ç©¶äº’è¡¥æ€§
  - âœ… "æˆ‘çš„ X æ–¹å‘ä¸ Prof.A çš„ Y æ–¹å‘å½¢æˆå¤©ç„¶äº’è¡¥ï¼Œå…±åŒè¦†ç›–ä» Z1 åˆ° Z2 çš„å®Œæ•´ç ”ç©¶èŒƒå›´"
  - âŒ ç”³è¯·ä¸ç°æœ‰æ•™æˆ**å®Œå…¨é‡å **çš„æ–¹å‘
- å±•ç¤º"æ¡¥æ¢"ä»·å€¼ï¼šè¿æ¥ HCI å°ç»„ä¸ä¸»æµ CS æ•™æˆ

#### Research Statement
- å±•ç¤ºä¸ç°æœ‰ç ”ç©¶çš„ååŒæ•ˆåº”ï¼ˆè€Œéç«äº‰ï¼‰
- å¼ºè°ƒç ”ç©¶çš„ç¤¾ä¼š/åº”ç”¨ä»·å€¼ï¼ˆæ¯” pure_pioneer æ›´å¯ä»¥ç”¨"äºº"çš„è¯­è¨€ï¼‰

#### Teaching Statement
- å±•ç¤ºè¯¾ç¨‹å¦‚ä½•ä¸ç°æœ‰è¯¾ç¨‹æ‹¼æˆå®Œæ•´ HCI Trackï¼ˆ"ç›®å‰å·²æœ‰ X å’Œ Yï¼Œæˆ‘å¯ä»¥è¡¥ Z"ï¼‰
- ä»ç›®æ ‡ç³» catalog æ‰¾**ç¼ºå£è¯¾ç¨‹**ï¼Œæå‡ºè¡¥å…¨æ–¹æ¡ˆ
- åˆ—å‡ºèƒ½å¸®åŠ©å»ºç«‹ç¡•åšé¡¹ç›®çš„è¯¾ç¨‹

---

### builder_in_rich_ecosystemï¼ˆtarget=few, faculty=manyï¼‰

**äººè®¾ï¼š** å»ºè®¾è€… + ä¸°å¯Œç”Ÿæ€ã€‚ç±»ä¼¼ builderï¼Œä½†å¯æå‡ºæ›´å¤§è§„æ¨¡çš„å€¡è®®ã€‚

#### ç‰¹æ®Šç­–ç•¥
- å¯æå‡ºå»ºç«‹**è·¨ç³»ç ”ç©¶ä¸­å¿ƒ**æˆ–**ç¡•å£«é¡¹ç›®**
- åˆ©ç”¨å­¦é™¢ç°æœ‰ HCI èµ„æºä½œä¸ºä¾æ‰˜ï¼Œé™ä½é£é™©æ„Ÿ
- æ¯” builder æ›´å¯ä»¥å±•ç¤º"é¢†å¯¼åŠ›"æ„¿æ™¯

---

### specialistï¼ˆtarget=many, faculty=manyï¼‰

**äººè®¾ï¼š** ä¸“å®¶ã€‚HCI æœ¬èº«æ²¡æœ‰ç¨€ç¼ºæ€§ï¼Œå¿…é¡»æœ‰"ç»æ´»"ã€‚

#### Cover Letter
- æ„¿æ™¯é©±åŠ¨ï¼šæå‡º**æ–°å­é¢†åŸŸ**æˆ–æ–°ç ”ç©¶è®®ç¨‹ï¼ˆä¸ä»…æ˜¯ä½ åšè¿‡ä»€ä¹ˆï¼‰
- å±•ç¤ºè·¨å­¦é™¢åˆä½œèƒ½åŠ›å’Œå­¦æœ¯é¢†å¯¼åŠ›
- å¼•ç”¨ç›®æ ‡é™¢ç³»æ•™æˆçš„å·¥ä½œï¼šå®šä½è€Œéå¥‰æ‰¿ï¼ˆ"Prof.X è§£å†³äº† Aï¼Œæˆ‘å°† A å’Œ B ç»“åˆå¼€å¯ C"ï¼‰

#### Research Statement
- ç†è®ºè´¡çŒ® > ç³»ç»Ÿè´¡çŒ®
- å±•ç¤º"ç¬¬äºŒé˜¶å½±å“"ï¼šå·¥å…·ä½¿ç”¨é‡ã€æ•°æ®é›†ä¸‹è½½é‡ã€æ”¿ç­–é‡‡çº³
- å¼ºè°ƒ Community Serviceï¼ˆWorkshop Organizer, AC ç­‰è§’è‰²ï¼‰

#### Teaching Statement
- å·¥ä½œå®¤æ•™å­¦æ³•ï¼ˆStudio Modelï¼‰ã€é¡¹ç›®åˆ¶å­¦ä¹ ï¼ˆPBLï¼‰
- åšå£«æŒ‡å¯¼ç†å¿µï¼ˆè¿™é‡Œæ‹›çš„ä¸åªæ˜¯ç ”ç©¶å‘˜ï¼Œè€Œæ˜¯æœªæ¥çš„å­¦æœ¯é¢†è¢–ï¼‰
- ä» catalog ä¸­é€‰**é«˜é˜¶/ç ”ç©¶ç”Ÿ** HCI è¯¾ç¨‹

---

## å››ã€ç‚¹åç­–ç•¥ï¼ˆé€šç”¨è§„åˆ™ï¼‰

1. **ä¼˜å…ˆ**ç‚¹åç›®æ ‡ç³»å†…æœ‰ç ”ç©¶äº¤é›†çš„æ•™æˆï¼ˆå³ä½¿é HCI æ–¹å‘ï¼‰
2. ç›®æ ‡ç³»åŒ¹é…ä¸è¶³æ—¶ï¼Œ**è¡¥å……**åŒæ ¡å…¶ä»–ç³» HCI æ•™æˆ
3. åŒæ ¡å¤šç³»æŠ•é€’æ—¶ï¼šæ¯ä»½ææ–™åªç‚¹åè¯¥ç³» + è·¨ç³»åˆä½œå¯¹è±¡ï¼Œ**ä¸æå¦ä¸€ä»½ç”³è¯·**

## äº”ã€è¯¾ç¨‹åŒ¹é…è§„åˆ™

1. Step 2 é¡»çˆ¬å–ç›®æ ‡ç³» course catalogï¼ˆäº”å±‚ fallbackï¼‰
2. ä» catalog è¯†åˆ« Sophia èƒ½æ•™çš„è¯¾ç¨‹ï¼ˆæ ¸å¿ƒè¯¾ + é€‰ä¿®è¯¾ï¼‰
3. æ ¹æ®å¯†åº¦ç­–ç•¥è°ƒæ•´å‘ˆç°é¡ºåºï¼š
   - **pioneer ç³»åˆ—**: CS æ ¸å¿ƒè¯¾åœ¨å‰ï¼ŒHCI è¯¾åœ¨åï¼ˆä½œä¸ºæ–°è¯¾ï¼‰
   - **builder ç³»åˆ—**: äº’è¡¥è¯¾ç¨‹åœ¨å‰ï¼ˆå¡«è¡¥ HCI Track ç¼ºå£ï¼‰ï¼Œåˆ—è¯¾ç¨‹ç¼–å·
   - **specialist**: é«˜é˜¶/ç ”ç©¶ç”Ÿ HCI è¯¾åœ¨å‰

## å…­ã€å‚è€ƒèµ„æ–™

- åŸå§‹ç­–ç•¥æŠ¥å‘Šï¼š`general/research_job_rules/å¤§å­¦æ•™èŒç”³è¯·ï¼šHCIç ”ç©¶è€…æ•°é‡ç­–ç•¥.md`
- è®¾è®¡æ–‡æ¡£ï¼š`overseas_pipeline/docs/plans/2026-02-19-hci-density-strategy-design.md`
```

**Step 3: éªŒè¯æ–‡ä»¶å­˜åœ¨**
```bash
ls -la overseas_pipeline/strategies/hci_density_strategy.md
```

**Step 4: Commit**
```bash
git add overseas_pipeline/strategies/hci_density_strategy.md
git commit -m "feat: add HCI density strategy guide for Step 2/3"
```

---

## Task 2: å®ç° hci_density_classifier.py

**Files:**
- Create: `overseas_pipeline/src/hci_density_classifier.py`

**Step 1: å†™å…¥è„šæœ¬**

```python
#!/usr/bin/env python3
"""
hci_density_classifier.py -- Step 1 è¾…åŠ©ï¼šHCI å¯†åº¦è‡ªåŠ¨åˆ†ç±»

ä» faculty_data.json ä¸­è¯»å– faculty åˆ—è¡¨ï¼Œ
æŒ‰ research_interests åŒ¹é… HCI å…³é”®è¯ï¼Œ
æ¨æ–­åŒå±‚å¯†åº¦åˆ†ç±»ï¼ˆtarget_dept + faculty_wideï¼‰ï¼Œ
å†™å› faculty_data.json çš„ hci_density å­—æ®µã€‚

ç”¨æ³•:
  python hci_density_classifier.py --input output/monash_university/faculty_data.json
  python hci_density_classifier.py --input output/monash_university/faculty_data.json --target-dept "DSAI"
"""

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path

# HCI ç›¸å…³å…³é”®è¯ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
HCI_KEYWORDS = [
    "hci", "human-computer interaction", "human computer interaction",
    "cscw", "computer-supported cooperative work",
    "human-ai interaction", "human ai interaction",
    "ux", "user experience", "user interface", "ui design",
    "accessibility", "inclusive design", "assistive technology",
    "interaction design", "interaction technique",
    "user study", "user research", "usability",
    "participatory design", "co-design",
    "information visualization", "visual analytics",
    "social computing", "computer-mediated communication",
    "augmented reality", "virtual reality", "mixed reality",
    "wearable computing", "ubiquitous computing", "ubicomp",
    "tangible computing", "tangible interface",
    "human factors", "ergonomics",
    "design research", "design thinking",
    "human-centered", "human centered", "people-centered",
    "end-user", "end user computing",
    "conversational agent", "conversational interface",
    "intelligent user interface",
    "explainability", "interpretability",  # ä¸ HCI äº¤å‰çš„ AI æ–¹å‘
]

STRATEGY_MATRIX = {
    ("none", "none"):   "pure_pioneer",
    ("none", "few"):    "pioneer_with_few_allies",
    ("none", "many"):   "pioneer_with_allies",
    ("few",  "none"):   "builder",          # ç½•è§
    ("few",  "few"):    "builder",
    ("few",  "many"):   "builder_in_rich_ecosystem",
    ("many", "many"):   "specialist",
}


def count_to_level(count: int) -> str:
    if count == 0:
        return "none"
    elif count <= 3:
        return "few"
    else:
        return "many"


def is_hci_researcher(faculty: dict, keywords: list[str]) -> bool:
    interests = " ".join(faculty.get("research_interests", [])).lower()
    return any(kw.lower() in interests for kw in keywords)


def classify(faculty_data: dict, target_dept_name: str | None, keywords: list[str]) -> dict:
    all_faculty = faculty_data.get("faculty", [])
    default_dept = faculty_data.get("department", "")

    target_dept = target_dept_name or default_dept

    target_hci = []
    wide_hci = []

    for f in all_faculty:
        if not is_hci_researcher(f, keywords):
            continue
        dept = f.get("department", default_dept)
        # ç®€å•å­—ç¬¦ä¸²åŒ…å«åŒ¹é…ï¼ˆå®½æ¾ï¼‰
        if target_dept.lower() in dept.lower() or dept.lower() in target_dept.lower():
            target_hci.append(f["name"])
        else:
            wide_hci.append(f["name"])

    target_level = count_to_level(len(target_hci))
    wide_level = count_to_level(len(wide_hci))

    strategy = STRATEGY_MATRIX.get(
        (target_level, wide_level),
        "builder"  # fallback
    )

    return {
        "target_dept": {
            "level": target_level,
            "count": len(target_hci),
            "hci_members": target_hci,
            "note": f"[auto] {len(target_hci)} HCI researchers in {target_dept}",
        },
        "faculty_wide": {
            "level": wide_level,
            "count": len(wide_hci),
            "hci_members": wide_hci,
            "note": f"[auto] {len(wide_hci)} HCI researchers in other departments",
        },
        "strategy": strategy,
        "strategy_rationale": "",  # agent åç»­è¡¥å……
        "classified_at": datetime.now().strftime("%Y-%m-%d"),
        "keywords_used": len(keywords),
    }


def main():
    parser = argparse.ArgumentParser(description="HCI density classifier for faculty_data.json")
    parser.add_argument("--input", required=True, help="Path to faculty_data.json")
    parser.add_argument("--target-dept", help="Target department name (overrides faculty_data.department)")
    parser.add_argument("--dry-run", action="store_true", help="Print result without writing")
    args = parser.parse_args()

    input_path = Path(args.input)
    if not input_path.exists():
        print(f"ERROR: {input_path} not found", file=sys.stderr)
        sys.exit(1)

    with open(input_path, encoding="utf-8") as f:
        faculty_data = json.load(f)

    result = classify(faculty_data, args.target_dept, HCI_KEYWORDS)

    print("\n=== HCI Density Classification ===")
    print(f"Target dept: {result['target_dept']['level']} ({result['target_dept']['count']} people)")
    if result['target_dept']['hci_members']:
        print(f"  Members: {', '.join(result['target_dept']['hci_members'])}")
    print(f"Faculty wide: {result['faculty_wide']['level']} ({result['faculty_wide']['count']} people)")
    if result['faculty_wide']['hci_members']:
        print(f"  Members: {', '.join(result['faculty_wide']['hci_members'])}")
    print(f"Strategy: {result['strategy']}")

    if args.dry_run:
        print("\n[dry-run] Not writing to file.")
        return

    faculty_data["hci_density"] = result

    with open(input_path, "w", encoding="utf-8") as f:
        json.dump(faculty_data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ Written to {input_path}")


if __name__ == "__main__":
    main()
```

**Step 2: ç”¨ç°æœ‰æµ‹è¯•æ•°æ®éªŒè¯**
```bash
python overseas_pipeline/src/hci_density_classifier.py \
  --input overseas_pipeline/output/monash_university_0218/faculty_data.json \
  --target-dept "DSAI" \
  --dry-run
```

æœŸæœ›è¾“å‡ºï¼ˆå¤§è‡´ï¼‰ï¼š
```
=== HCI Density Classification ===
Target dept: none (0 people)
Faculty wide: many (3+ people)
Strategy: pioneer_with_allies
[dry-run] Not writing to file.
```

**Step 3: çœŸå®å†™å…¥éªŒè¯**
```bash
# å…ˆå¤‡ä»½
cp overseas_pipeline/output/monash_university_0218/faculty_data.json \
   overseas_pipeline/output/monash_university_0218/faculty_data.json.bak

python overseas_pipeline/src/hci_density_classifier.py \
  --input overseas_pipeline/output/monash_university_0218/faculty_data.json \
  --target-dept "DSAI"

# æ£€æŸ¥ hci_density å­—æ®µæ˜¯å¦å†™å…¥
python3 -c "
import json
d = json.load(open('overseas_pipeline/output/monash_university_0218/faculty_data.json'))
print(json.dumps(d.get('hci_density', {}), indent=2, ensure_ascii=False))
"
```

**Step 4: Commit**
```bash
git add overseas_pipeline/src/hci_density_classifier.py
git commit -m "feat: add HCI density classifier (Step 1 code layer)"
```

---

## Task 3: å®ç° course_catalog_scraper.py

**Files:**
- Create: `overseas_pipeline/src/course_catalog_scraper.py`

**Step 1: å†™å…¥è„šæœ¬**

```python
#!/usr/bin/env python3
"""
course_catalog_scraper.py -- Step 1 è¾…åŠ©ï¼šè¯¾ç¨‹ä½“ç³»æŠ“å–

æŠ“å–ç›®æ ‡é™¢ç³»è¯¾ç¨‹é¡µé¢ï¼Œæå–è¯¾ç¨‹åˆ—è¡¨ï¼Œ
å†™å…¥ faculty_data.json çš„ department_courses å­—æ®µã€‚

äº”å±‚ fallback ç­–ç•¥ï¼š
  Layer 1:   curl + browser UA
  Layer 1.5: Jina Reader (https://r.jina.ai/)
  Layer 2:   Tavily Extract API
  Layer 2.5: Wayback Machine
  Layer 3:   Tavily Search APIï¼ˆæœç´¢è¯¾ç¨‹é¡µé¢ï¼‰

ç”¨æ³•:
  python course_catalog_scraper.py \
    --url "https://www.monash.edu/it/dsai/courses" \
    --output overseas_pipeline/output/monash_university/faculty_data.json

  python course_catalog_scraper.py \
    --url "https://www.monash.edu/it/dsai/courses" \
    --dry-run
"""

import argparse
import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path

try:
    import requests
except ImportError:
    print("ERROR: pip install requests", file=sys.stderr)
    sys.exit(1)

TAVILY_API_KEY = os.environ.get("TAVILY_API_KEY", "")
TIMEOUT = 20

HCI_COURSE_KEYWORDS = [
    "hci", "human-computer", "interaction design", "user experience",
    "ux", "usability", "accessibility", "human factors",
    "interface", "user interface", "human-ai", "conversational",
    "visualization", "information design",
]

BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9",
}


def log(msg):
    print(f"[course_scraper] {msg}", flush=True)


def is_blocked(text: str) -> bool:
    signals = ["just a moment", "cf_chl_opt", "challenge-platform",
               "enable javascript", "403 forbidden", "access denied"]
    low = text.lower()
    return any(s in low for s in signals) or len(text) < 300


# --- Fetch layers ---

def layer1_curl(url: str) -> str | None:
    log(f"Layer 1: curl {url}")
    try:
        resp = requests.get(url, headers=BROWSER_HEADERS, timeout=TIMEOUT)
        if is_blocked(resp.text):
            log("  âœ— Blocked (Cloudflare/WAF)")
            return None
        log(f"  âœ“ {len(resp.text)} chars")
        return resp.text
    except Exception as e:
        log(f"  âœ— {e}")
        return None


def layer1_5_jina(url: str) -> str | None:
    log(f"Layer 1.5: Jina Reader")
    try:
        resp = requests.get(f"https://r.jina.ai/{url}",
                            headers={"User-Agent": BROWSER_HEADERS["User-Agent"]},
                            timeout=TIMEOUT)
        if len(resp.text) < 500 or "error" in resp.text[:200].lower():
            log("  âœ— Jina returned short/error response")
            return None
        log(f"  âœ“ {len(resp.text)} chars")
        return resp.text
    except Exception as e:
        log(f"  âœ— {e}")
        return None


def layer2_tavily_extract(url: str) -> str | None:
    if not TAVILY_API_KEY:
        log("  âš  TAVILY_API_KEY not set, skipping Layer 2")
        return None
    log(f"Layer 2: Tavily Extract")
    try:
        resp = requests.post(
            "https://api.tavily.com/extract",
            headers={"Authorization": f"Bearer {TAVILY_API_KEY}",
                     "Content-Type": "application/json"},
            json={"urls": [url]},
            timeout=TIMEOUT,
        )
        data = resp.json()
        results = data.get("results", [])
        if not results:
            log("  âœ— No results")
            return None
        content = results[0].get("raw_content", "")
        log(f"  âœ“ {len(content)} chars")
        return content
    except Exception as e:
        log(f"  âœ— {e}")
        return None


def layer2_5_wayback(url: str) -> str | None:
    log(f"Layer 2.5: Wayback Machine")
    for year in ["2024", "2023"]:
        wayback_url = f"https://web.archive.org/web/{year}/{url}"
        try:
            resp = requests.get(wayback_url, headers=BROWSER_HEADERS, timeout=TIMEOUT)
            if not is_blocked(resp.text) and len(resp.text) > 500:
                log(f"  âœ“ {len(resp.text)} chars (year={year})")
                return resp.text
        except Exception as e:
            log(f"  âœ— year={year}: {e}")
    return None


def layer3_tavily_search(url: str, school: str = "") -> str | None:
    if not TAVILY_API_KEY:
        log("  âš  TAVILY_API_KEY not set, skipping Layer 3")
        return None
    domain = url.split("/")[2] if "//" in url else url
    query = f"site:{domain} course catalog {school} courses list"
    log(f"Layer 3: Tavily Search '{query}'")
    try:
        resp = requests.post(
            "https://api.tavily.com/search",
            headers={"Authorization": f"Bearer {TAVILY_API_KEY}",
                     "Content-Type": "application/json"},
            json={"query": query, "max_results": 5, "include_raw_content": True},
            timeout=TIMEOUT,
        )
        data = resp.json()
        results = data.get("results", [])
        if not results:
            log("  âœ— No results")
            return None
        combined = "\n\n".join(r.get("content", "") for r in results)
        log(f"  âœ“ {len(combined)} chars from {len(results)} results")
        return combined
    except Exception as e:
        log(f"  âœ— {e}")
        return None


def fetch_with_fallback(url: str, school: str = "") -> tuple[str | None, str]:
    """äº”å±‚ fallbackï¼Œè¿”å› (content, layer_used)"""
    content = layer1_curl(url)
    if content:
        return content, "layer1_curl"

    content = layer1_5_jina(url)
    if content:
        return content, "layer1.5_jina"

    content = layer2_tavily_extract(url)
    if content:
        return content, "layer2_tavily_extract"

    content = layer2_5_wayback(url)
    if content:
        return content, "layer2.5_wayback"

    content = layer3_tavily_search(url, school)
    if content:
        return content, "layer3_tavily_search"

    return None, "all_failed"


# --- Course extraction (heuristic, agent will refine) ---

def is_hci_course(name: str) -> bool:
    low = name.lower()
    return any(kw in low for kw in HCI_COURSE_KEYWORDS)


def extract_courses_heuristic(text: str) -> list[dict]:
    """
    ç®€å•å¯å‘å¼æå–ï¼šåœ¨æ–‡æœ¬ä¸­åŒ¹é…è¯¾ç¨‹ç¼–å· + åç§°æ¨¡å¼ã€‚
    Agent ä¼šåœ¨æ­¤åŸºç¡€ä¸Šå®¡æŸ¥å’Œè¡¥å……ã€‚
    """
    courses = []
    # å¸¸è§è¯¾ç¨‹ç¼–å·æ ¼å¼ï¼šFIT5145, CS101, COMP3702, INFO4112 ç­‰
    pattern = re.compile(
        r'\b([A-Z]{2,6}\s*\d{3,5}[A-Z]?)\s*[:\-â€“]?\s*([^\n\r,;]{10,80})',
        re.MULTILINE
    )
    for match in pattern.finditer(text):
        code = match.group(1).strip().replace(" ", "")
        name = match.group(2).strip().rstrip(".,;")
        if len(name) < 5:
            continue
        # ç²—ç•¥åˆ¤æ–­æ˜¯å¦æ˜¯æœ¬ç§‘/ç ”ç©¶ç”Ÿï¼ˆç¼–å·æ•°å­—éƒ¨åˆ†ï¼‰
        digits = re.search(r'\d+', code)
        level = "unknown"
        if digits:
            n = int(digits.group())
            if n >= 5000:
                level = "postgrad"
            elif n >= 3000:
                level = "undergrad_advanced"
            else:
                level = "undergrad"

        courses.append({
            "code": code,
            "name": name,
            "level": level,
            "hci_relevant": is_hci_course(name),
        })

    # å»é‡ï¼ˆæŒ‰ codeï¼‰
    seen = set()
    unique = []
    for c in courses:
        if c["code"] not in seen:
            seen.add(c["code"])
            unique.append(c)

    return unique


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--url", required=True, help="Course catalog URL")
    parser.add_argument("--output", help="Path to faculty_data.json to update")
    parser.add_argument("--school", default="", help="School name (for search fallback)")
    parser.add_argument("--dry-run", action="store_true")
    args = parser.parse_args()

    content, layer = fetch_with_fallback(args.url, args.school)

    if not content:
        print("ERROR: All five layers failed. Manual paste required.", file=sys.stderr)
        sys.exit(1)

    courses = extract_courses_heuristic(content)
    log(f"Extracted {len(courses)} courses ({sum(1 for c in courses if c['hci_relevant'])} HCI-relevant)")

    result = {
        "department_courses": courses,
        "course_catalog_url": args.url,
        "course_catalog_scrape_date": datetime.now().strftime("%Y-%m-%d"),
        "course_fetch_layer": layer,
        "course_count": len(courses),
    }

    print("\n=== Course Catalog ===")
    for c in courses[:10]:
        tag = "ğŸ”µ" if c["hci_relevant"] else "  "
        print(f"  {tag} [{c['level']}] {c['code']}: {c['name']}")
    if len(courses) > 10:
        print(f"  ... and {len(courses) - 10} more")

    if args.dry_run:
        print("\n[dry-run] Not writing.")
        return

    if not args.output:
        print("WARNING: --output not specified. Printing JSON only.")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        return

    output_path = Path(args.output)
    if output_path.exists():
        with open(output_path, encoding="utf-8") as f:
            faculty_data = json.load(f)
    else:
        faculty_data = {}

    faculty_data.update(result)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(faculty_data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ Written to {output_path}")


if __name__ == "__main__":
    main()
```

**Step 2: dry-run æµ‹è¯•ï¼ˆç”¨å·²æœ‰å­¦æ ¡æ•°æ®ï¼‰**
```bash
python overseas_pipeline/src/course_catalog_scraper.py \
  --url "https://www.monash.edu/it/dsai/courses" \
  --school "Monash University DSAI" \
  --dry-run
```

è§‚å¯Ÿï¼šäº”å±‚ä¸­å“ªå±‚æˆåŠŸã€æå–åˆ°å¤šå°‘è¯¾ç¨‹ã€‚

**Step 3: Commit**
```bash
git add overseas_pipeline/src/course_catalog_scraper.py
git commit -m "feat: add course catalog scraper with five-layer fallback (Step 1 code layer)"
```

---

## Task 4: æ›´æ–° CLAUDE.md

**Files:**
- Modify: `overseas_pipeline/CLAUDE.md`

éœ€è¦æ›´æ–°ä¸‰ä¸ªåœ°æ–¹ï¼š

**Step 1: ç½‘é¡µæŠ“å–è§„åˆ™ï¼ˆé¡¶éƒ¨ï¼‰â€” ä¸‰å±‚æ”¹äº”å±‚**

å°†ï¼š
```
1. **Layer 1**: WebFetch / Jina Reader / curl + browser UA
2. **Layer 2**: Tavily Extract APIï¼ˆ`$TAVILY_API_KEY`ï¼‰
3. **Layer 3**: Tavily Search API
```

æ”¹ä¸ºï¼š
```
1. **Layer 1**: curl + browser UA
2. **Layer 1.5**: Jina Readerï¼ˆ`https://r.jina.ai/`ï¼Œå…è´¹æ—  keyï¼Œé€‚åˆ Medium/Cloudflare åœºæ™¯ï¼‰
3. **Layer 2**: Tavily Extract APIï¼ˆ`$TAVILY_API_KEY`ï¼‰
4. **Layer 2.5**: Wayback Machineï¼ˆ`web.archive.org/web/{year}/åŸURL`ï¼Œå…è´¹ï¼Œé€‚åˆåšå®¢/ä¸ªäººç½‘ç«™ï¼‰
5. **Layer 3**: Tavily Search API
```

**Step 2: Step 1 æµç¨‹ â€” æ–°å¢æ­¥éª¤ 6/7/8**

åœ¨"ç ”ç©¶ {å­¦æ ¡å}"çš„æ‰§è¡Œæ­¥éª¤ä¸­ï¼Œç°æœ‰æ­¥éª¤ 5/6 ä¹‹åè¿½åŠ ï¼š

```markdown
6. **HCI å¯†åº¦åˆ†ç±»ï¼ˆCodeï¼‰**ï¼š
   ```
   python overseas_pipeline/src/hci_density_classifier.py \
     --input output/{school_id}/faculty_data.json \
     [--target-dept "{ç›®æ ‡ç³»åç§°}"]
   ```
   â†’ è‡ªåŠ¨æ¨æ–­åŒå±‚å¯†åº¦ï¼ˆtarget_dept + faculty_wideï¼‰å’Œç­–ç•¥æ ‡ç­¾ï¼Œå†™å…¥ `faculty_data.json` çš„ `hci_density` å­—æ®µ
   â†’ **agent éšåè¡¥å…… `strategy_rationale`**ï¼ˆè‡ªç„¶è¯­è¨€è§£é‡Šï¼Œæ£€æŸ¥è¾¹ç•Œæƒ…å†µï¼‰

7. **è¯¾ç¨‹ä½“ç³»æŠ“å–ï¼ˆCodeï¼‰**ï¼š
   ```
   python overseas_pipeline/src/course_catalog_scraper.py \
     --url "{ç›®æ ‡ç³»è¯¾ç¨‹é¡µé¢URL}" \
     --output output/{school_id}/faculty_data.json \
     --school "{å­¦æ ¡å}"
   ```
   â†’ äº”å±‚ fallback æŠ“å–è¯¾ç¨‹åˆ—è¡¨ï¼Œå†™å…¥ `faculty_data.json` çš„ `department_courses` å­—æ®µ
   â†’ å¦‚è¯¾ç¨‹é¡µé¢ URL æœªçŸ¥ï¼Œç”¨ Tavily æœç´¢ `site:{domain} course catalog`
   â†’ **agent éšåå®¡æŸ¥**ï¼šè¯†åˆ« Sophia èƒ½æ•™çš„è¯¾ï¼ŒæŒ‰å¯†åº¦ç­–ç•¥æ’åºï¼ˆpioneerâ†’CS æ ¸å¿ƒè¯¾åœ¨å‰ï¼›builderâ†’äº’è¡¥è¯¾ç¨‹åœ¨å‰ï¼›specialistâ†’é«˜é˜¶è¯¾åœ¨å‰ï¼‰

8. **agent å®¡æŸ¥è¡¥å……**ï¼š
   - æ£€æŸ¥å¯†åº¦åˆ†ç±»æ˜¯å¦æœ‰è¾¹ç•Œé—æ¼ï¼ˆå¦‚æŸæ•™æˆå†™ "computational social science" ä½†å®é™…åš HCIï¼‰
   - è¡¥å…… `hci_density.strategy_rationale` è‡ªç„¶è¯­è¨€è§£é‡Š
   - å°†å¯†åº¦åˆ¤æ–­ + è¯¾ç¨‹åŒ¹é…æ¦‚è§ˆå†™å…¥ `step1_summary.md`ï¼Œä¾› Sophia å¼‚æ­¥å®¡æŸ¥
   - Sophia æœ‰å¼‚è®®æ—¶ç»™ comment è¦†ç›–ï¼Œæ—  comment åˆ™æµç¨‹ç»§ç»­
```

**Step 3: Step 2 æµç¨‹ â€” æ–°å¢ HCI å¯†åº¦ç­–ç•¥ç»´åº¦**

åœ¨"åˆ†æ {å­¦æ ¡å}"çš„æ‰§è¡Œæ­¥éª¤ 6ï¼ˆè§„åˆ™å†²çªæ£€æŸ¥ï¼‰ä¹‹å‰æ’å…¥ï¼š

```markdown
5b. è¯»å– HCI å¯†åº¦ç­–ç•¥ï¼š
   - è¯»å– `overseas_pipeline/strategies/hci_density_strategy.md`
   - ä» `faculty_data.json` è·å– `hci_density.strategy`
   - ç¡®å®šç‚¹åä¼˜å…ˆçº§ï¼ˆç›®æ ‡ç³»æ•™æˆä¼˜å…ˆ â†’ å…¶ä»–ç³»è¡¥å……ï¼‰
   - ç¡®å®šè¯¾ç¨‹åŒ¹é…é¡ºåºï¼ˆæŒ‰ç­–ç•¥ç±»å‹ï¼‰
```

åœ¨ `fit_report.md` æ ¼å¼ä¸­æ–°å¢ç»´åº¦ï¼š

```markdown
### HCI å¯†åº¦ç­–ç•¥åˆ†æ (X/10)
- ç›®æ ‡ç³» HCI å¯†åº¦ï¼š{level}ï¼ˆ{count} äººï¼š{names}ï¼‰
- å­¦é™¢ HCI å¯†åº¦ï¼š{level}ï¼ˆ{count} äººï¼š{names}ï¼‰
- æ¨èç­–ç•¥ï¼š`{strategy}`
- ç­–ç•¥è¦ç‚¹ï¼š
  - {è¯„å§”æ„æˆå¯¹åº”çš„ä¿®è¾å»ºè®®}
  - ç‚¹åä¼˜å…ˆçº§ï¼š{ç›®æ ‡ç³»äº¤é›†æ•™æˆ} â†’ {å…¶ä»–ç³»è¡¥å……æ•™æˆ}
  - {å¦‚ pioneer_with_alliesï¼šè®ºè¯ä¸ºä»€ä¹ˆå±äºç›®æ ‡ç³»çš„å…³é”®ç‚¹}

### å„ææ–™è°ƒæ•´å»ºè®®

#### Cover Letter
- **å¯†åº¦ç­–ç•¥** [`{strategy}`]ï¼š{å…·ä½“ä¿®è¾å»ºè®®ï¼Œå¼•ç”¨ç­–ç•¥æ–‡ä»¶å¯¹åº”ç« èŠ‚}
- **ç‚¹åå»ºè®®**ï¼š
  - ç›®æ ‡ç³»ï¼ˆä¼˜å…ˆï¼‰ï¼š{æ•™æˆåˆ—è¡¨ + åˆä½œç‚¹}
  - è·¨ç³»è¡¥å……ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰ï¼š{æ•™æˆåˆ—è¡¨ + åˆä½œç‚¹}

#### Teaching Statement
- **å¯†åº¦ç­–ç•¥** [`{strategy}`]ï¼š{è¯¾ç¨‹å‘ˆç°é¡ºåºå»ºè®®}
- **ç›®æ ‡ç³»è¯¾ç¨‹åŒ¹é…**ï¼š
  - å¯æ•™çš„ç°æœ‰è¯¾ï¼š{è¯¾ç¨‹ç¼–å· + åç§°}
  - å¯å¼€è®¾æ–°è¯¾ï¼š{è¯¾ç¨‹ç¼–å· + åç§°}
  - è”åˆå¼€è¯¾å»ºè®®ï¼š{ä¸å“ªä¸ªç³»åˆä½œï¼Œå¼€ä»€ä¹ˆè¯¾}
```

**Step 4: Step 3 æµç¨‹ â€” æ–°å¢å¯†åº¦ç­–ç•¥è¯»å–å’Œä¸€è‡´æ€§æ£€æŸ¥**

åœ¨"ç”Ÿæˆææ–™ {å­¦æ ¡å}"çš„æ‰§è¡Œæ­¥éª¤ 1 å‰è¿½åŠ ï¼š

```markdown
0. è¯»å–å¯†åº¦ç­–ç•¥æ–‡ä»¶ï¼š
   - `overseas_pipeline/strategies/hci_density_strategy.md`
   - `faculty_data.json` ä¸­çš„ `hci_density` å’Œ `department_courses` å­—æ®µ
   - ç¡®å®šæœ¬æ¬¡ç”Ÿæˆçš„ç­–ç•¥ç±»å‹ï¼ˆ`pure_pioneer` / `pioneer_with_allies` / ç­‰ï¼‰

ï¼ˆå®Œæˆåï¼‰å¦‚å­˜åœ¨ `related_applications` å­—æ®µï¼š
   - è¯»å–åŒæ ¡å…¶ä»–æŠ•é€’çš„ fit_report.md
   - åœ¨æ¯ä»½ notes.md çš„"ç»™ Sophia çš„å®¡æ ¸é‡ç‚¹"ä¸­è¿½åŠ åŒæ ¡ä¸€è‡´æ€§æ£€æŸ¥æ®µè½ï¼š
     ```markdown
     ## åŒæ ¡å¤šç³»ä¸€è‡´æ€§æ£€æŸ¥
     - æœ¬æ ¡å¦ä¸€ä»½ç”³è¯·ï¼š{department}ï¼ˆ{strategy} ç­–ç•¥ï¼ŒçŠ¶æ€ï¼š{status}ï¼‰
     - æ ¸å¿ƒå™äº‹ä¸€è‡´æ€§ï¼šâœ…/âš  {æè¿°ä¸¤ä»½ææ–™æ ¸å¿ƒå®šä½æ˜¯å¦ç»Ÿä¸€}
     - ä¾§é‡ç‚¹å·®å¼‚ï¼šæœ¬ç³»ç‰ˆï¼ˆ{ç®€è¿°}ï¼‰vs å¦ä¸€ç³»ç‰ˆï¼ˆ{ç®€è¿°}ï¼‰
     - âš  æ³¨æ„ï¼š{å…·ä½“æé†’ï¼Œå¦‚"ä¸¤ä»½ Cover Letter å‡æœªæåŠå¦ä¸€ä»½ç”³è¯·"ï¼Œæˆ–"Research Statement ç‚¹åæ•™æˆæ— é‡å "ç­‰}
     ```
```

**Step 5: éªŒè¯ CLAUDE.md æ²¡æœ‰æ ¼å¼æŸå**
```bash
wc -l overseas_pipeline/CLAUDE.md
head -30 overseas_pipeline/CLAUDE.md
```

**Step 6: Commit**
```bash
git add overseas_pipeline/CLAUDE.md
git commit -m "feat: update pipeline CLAUDE.md â€” five-layer fallback + HCI density integration"
```

---

## Task 5: éªŒè¯ç«¯åˆ°ç«¯ï¼ˆSmoke Testï¼‰

**ç”¨ç°æœ‰ Monash æ•°æ®è·‘ä¸€é Task 2/3 çš„çœŸå®å†™å…¥ï¼Œæ£€æŸ¥ faculty_data.json ç»“æ„å®Œæ•´æ€§**

**Step 1: è·‘å¯†åº¦åˆ†ç±»**
```bash
python overseas_pipeline/src/hci_density_classifier.py \
  --input overseas_pipeline/output/monash_university_0218/faculty_data.json \
  --target-dept "DSAI"
```

**Step 2: è·‘è¯¾ç¨‹æŠ“å–ï¼ˆdry-runï¼Œå› ä¸ºéœ€è¦ç½‘ç»œï¼‰**
```bash
python overseas_pipeline/src/course_catalog_scraper.py \
  --url "https://www.monash.edu/it/dsai/courses" \
  --school "Monash University" \
  --dry-run
```

**Step 3: æ£€æŸ¥ JSON ç»“æ„å®Œæ•´æ€§**
```bash
python3 -c "
import json
d = json.load(open('overseas_pipeline/output/monash_university_0218/faculty_data.json'))
fields = ['school', 'faculty', 'hci_density', 'scrape_date']
for f in fields:
    status = 'âœ…' if f in d else 'âŒ'
    print(f'{status} {f}')
hd = d.get('hci_density', {})
print(f'  strategy: {hd.get(\"strategy\")}')
print(f'  target_dept level: {hd.get(\"target_dept\", {}).get(\"level\")}')
print(f'  faculty_wide level: {hd.get(\"faculty_wide\", {}).get(\"level\")}')
"
```

**Step 4: æœ€ç»ˆ commitï¼ˆå¦‚æœ‰æ®‹ç•™ä¿®æ”¹ï¼‰**
```bash
git status
git add -p  # æŒ‰éœ€é€‰æ‹©
```

---

## å®ç°é¡ºåº

```
Task 1 (ç­–ç•¥æ–‡ä»¶) â†’ Task 2 (å¯†åº¦åˆ†ç±»è„šæœ¬) â†’ Task 3 (è¯¾ç¨‹æŠ“å–è„šæœ¬)
                                                        â†“
Task 4 (CLAUDE.md æ›´æ–°) â† éœ€è¦äº†è§£ Task 2/3 çš„è°ƒç”¨æ¥å£
                                                        â†“
                                               Task 5 (Smoke Test)
```

Task 1ã€2ã€3 å¯ä»¥å¹¶è¡Œï¼ŒTask 4 åœ¨ 2/3 å®Œæˆåè¿›è¡Œã€‚
